run_mode: "ft"
load_model: True
load_dir: "path/to/ckpt"
grad_acc_step: 32
num_epochs: 1
mode: decode
batch_size: 1
lr: 0.0001
l2: 0.1
selections: True
llm_max_length: 512
gnn_type: index
fuse_type: interleave
num_layers: 5

# check ./configs/inference_config.yaml for explanation of each parameter.
train_task_names:
  - mag240m
  - wikikg90m
  - arxiv_link
  - arxiv
  - pubmed_link
  - pubmed

sample_size_per_task:
  - 10000
  - 10000
  - 10000
  - 10000
  - 10000
  - 10000

hops:
  - 3
  - 3
  - 3
  - 3
  - 3
  - 3

train_max_nodes_per_hops:
  - 5
  - 5
  - 5
  - 5
  - 5
  - 5

ways: 10
instructs: True

eval_task_names:
  - cora_node
  - cora_link
  - wikics
  - products
  - expla_graph
  - fb15k237
  - scene_graph
  - protein_hs

inf_sample_size_per_task:
  - 200
  - 200
  - 200
  - 200
  - 200
  - 200
  - 200
  - 200

inf_hops:
  - 3
  - 3
  - 3
  - 3
  - -1
  - 3
  - -1
  - 3

inf_max_nodes_per_hops:
  - 10
  - 10
  - 10
  - 10
  - -1
  - 10
  - -1
  - 10

inf_ways:
  - 7
  - 2
  - 10
  - 10
  - 2
  - 10
  - -1
  - 10

inf_instructs:
  - True
  - True
  - True
  - True
  - True
  - True
  - True
  - True

inf_selections:
  - True
  - True
  - True
  - True
  - True
  - True
  - True
  - True

dec_lora: True